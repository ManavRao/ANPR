{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Plate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8d7e260ef684>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameters\n",
    "\n",
    "image_name = \"images/test_final.png\"\n",
    "final_plates = []\n",
    "confThreshold = 0.5      #Confidence threshold\n",
    "nmsThreshold = 0.4       #Non-maximum suppression threshold\n",
    "\n",
    "inpWidth = 416  #608     #Width of network's input image\n",
    "inpHeight = 416 #608     #Height of network's input image\n",
    "\n",
    "save_detector = True    #Save Intermedate outputs\n",
    "\n",
    "# Load names of classes\n",
    "classesFile = \"detection/classes.names\";\n",
    "\n",
    "classes = None\n",
    "with open(classesFile, 'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "# Configuration and weight files for the model\n",
    "modelConfiguration = \"detection/darknet-yolov3.cfg\";\n",
    "modelWeights = \"detection/lapi.weights\";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "net = cv.dnn.readNetFromDarknet(modelConfiguration, modelWeights)\n",
    "net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the output layers\n",
    "def getOutputsNames(net):\n",
    "    # Get the names of all the layers in the network\n",
    "    layersNames = net.getLayerNames()\n",
    "    # Get the names of the output layers, i.e. the layers with unconnected outputs\n",
    "    return [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the predicted bounding box\n",
    "def drawPred(classId, conf, left, top, right, bottom, num):\n",
    "    # Draw a bounding box.\n",
    "    #    cv.rectangle(frame, (left, top), (right, bottom), (255, 178, 50), 3)\n",
    "    global save_detector\n",
    "    global image_name\n",
    "    global final_plates\n",
    "    temp_11 = frame[top:bottom, left:right]\n",
    "    final_plates.append(temp_11.copy())\n",
    "        \n",
    "    if save_detector:\n",
    "        temp_name = image_name.split(\"/\")[-1].split(\".\")[0] + \"_test_\"+str(num)+\".jpg\"\n",
    "        cv.imwrite(temp_name , temp_11)\n",
    "        print(\"Number plate saved as\", temp_name)\n",
    "    \n",
    "    cv.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 3)\n",
    "\n",
    "\n",
    "    label = '%.2f' % conf\n",
    "\n",
    "    # Get the label for the class name and its confidence\n",
    "    if classes:\n",
    "        assert(classId < len(classes))\n",
    "        label = '%s:%s' % (classes[classId], label)\n",
    "\n",
    "    #Display the label at the top of the bounding box\n",
    "    labelSize, baseLine = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    top = max(top, labelSize[1])\n",
    "    cv.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine), (0, 0, 255), cv.FILLED)\n",
    "    #cv.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine),    (255, 255, 255), cv.FILLED)\n",
    "    cv.putText(frame, label, (left, top), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the bounding boxes with low confidence using non-maxima suppression\n",
    "def postprocess(frame, outs):\n",
    "    frameHeight = frame.shape[0]\n",
    "    frameWidth = frame.shape[1]\n",
    "\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    # Scan through all the bounding boxes output from the network and keep only the\n",
    "    # ones with high confidence scores. Assign the box's class label as the class with the highest score.\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        print(\"out.shape : \", out.shape)\n",
    "        for detection in out:\n",
    "            #if detection[4]>0.001:\n",
    "            scores = detection[5:]\n",
    "            classId = np.argmax(scores)\n",
    "            #if scores[classId]>confThreshold:\n",
    "            confidence = scores[classId]\n",
    "            if detection[4]>confThreshold:\n",
    "                print(detection[4], \" - \", scores[classId], \" - th : \", confThreshold)\n",
    "                print(detection)\n",
    "            if confidence > confThreshold:\n",
    "                center_x = int(detection[0] * frameWidth)\n",
    "                center_y = int(detection[1] * frameHeight)\n",
    "                width = int(detection[2] * frameWidth)\n",
    "                height = int(detection[3] * frameHeight)\n",
    "                left = int(center_x - width / 2)\n",
    "                top = int(center_y - height / 2)\n",
    "                classIds.append(classId)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([left, top, width, height])\n",
    "\n",
    "    # Perform non maximum suppression to eliminate redundant overlapping boxes with\n",
    "    # lower confidences.\n",
    "    indices = cv.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        left = box[0]\n",
    "        top = box[1]\n",
    "        width = box[2]\n",
    "        height = box[3]\n",
    "        drawPred(classIds[i], confidences[i], left, top, left + width, top + height, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image file\n",
    "if not os.path.isfile(image_name):\n",
    "    raise(\"Input image file \", image_name, \" doesn't exist\")\n",
    "\n",
    "cap = cv.VideoCapture(image_name)\n",
    "outputFile = image_name.split(\"/\")[-1].split(\".\")[0] +'_yolo_out_py.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape :  (507, 6)\n",
      "0.99919766  -  0.9988524  - th :  0.5\n",
      "[0.17183352 0.83535856 0.30102748 0.11200143 0.99919766 0.9988524 ]\n",
      "out.shape :  (2028, 6)\n",
      "0.9191908  -  0.9183305  - th :  0.5\n",
      "[0.11942302 0.3769694  0.18329705 0.04992956 0.9191908  0.9183305 ]\n",
      "0.7293875  -  0.0  - th :  0.5\n",
      "[0.81101346 0.72939175 0.2795067  0.08183558 0.7293875  0.        ]\n",
      "0.87159854  -  0.8712044  - th :  0.5\n",
      "[0.810263   0.7329991  0.27512008 0.08571084 0.87159854 0.8712044 ]\n",
      "0.8841035  -  0.88341874  - th :  0.5\n",
      "[0.16923203 0.83789635 0.3510276  0.11009272 0.8841035  0.88341874]\n",
      "out.shape :  (8112, 6)\n",
      "0.93100756  -  0.92871875  - th :  0.5\n",
      "[0.49120763 0.30527547 0.15747817 0.04117268 0.93100756 0.92871875]\n",
      "0.99979824  -  0.9995764  - th :  0.5\n",
      "[0.8386049  0.3527819  0.14071968 0.03558465 0.99979824 0.9995764 ]\n",
      "0.9999839  -  0.9998981  - th :  0.5\n",
      "[0.5099382  0.7965487  0.1225493  0.04255853 0.9999839  0.9998981 ]\n",
      "Number plate saved as test_final_test_6.jpg\n",
      "Number plate saved as test_final_test_5.jpg\n",
      "Number plate saved as test_final_test_0.jpg\n",
      "Number plate saved as test_final_test_4.jpg\n",
      "Number plate saved as test_final_test_1.jpg\n",
      "Number plate saved as test_final_test_2.jpg\n",
      "Done processing !!!\n",
      "Output file is stored as  test_final_yolo_out_py.jpg\n"
     ]
    }
   ],
   "source": [
    "while cv.waitKey(1) < 0:\n",
    "\n",
    "    # get frame from the video\n",
    "    hasFrame, frame = cap.read()\n",
    "\n",
    "    # Stop the program if reached end of video\n",
    "    if not hasFrame:\n",
    "        if save_detector:\n",
    "            print(\"Done processing !!!\")\n",
    "            print(\"Output file is stored as \", outputFile)\n",
    "        break\n",
    "\n",
    "    # Create a 4D blob from a frame.\n",
    "    blob = cv.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop=False)\n",
    "\n",
    "    # Sets the input to the network\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Runs the forward pass to get output of the output layers\n",
    "    outs = net.forward(getOutputsNames(net))\n",
    "\n",
    "    # Remove the bounding boxes with low confidence\n",
    "    postprocess(frame, outs)\n",
    "\n",
    "    # Put efficiency information. The function getPerfProfile returns the overall time for inference(t) and the timings for each of the layers(in layersTimes)\n",
    "    t, _ = net.getPerfProfile()\n",
    "    label = 'Inference time: %.2f ms' % (t * 1000.0 / cv.getTickFrequency())\n",
    "    #cv.putText(frame, label, (0, 15), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n",
    "\n",
    "    # Write the frame with the detection boxes\n",
    "    if save_detector:\n",
    "        cv.imwrite(outputFile, frame.astype(np.uint8));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 1\n",
    "rows = len(final_plates)\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = final_plates[i-1]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Plate Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import joblib\n",
    "import pytesseract\n",
    "from scipy.signal import find_peaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_ocr(img, ans):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    (thresh, im_bw) = cv2.threshold(img_gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    in_im_bw = cv2.bitwise_not(im_bw)\n",
    "    \n",
    "    if sum(im_bw.flatten()) < sum(in_im_bw.flatten()):\n",
    "        img = im_bw\n",
    "    else:\n",
    "        img = in_im_bw\n",
    "    #height\n",
    "    a,b = img.shape\n",
    "    x = np.sum(img, axis=1)\n",
    "\n",
    "    x = x*-1\n",
    "    mins, _ = find_peaks(x)\n",
    "    x = x*-1\n",
    "    y = [m for m in range(a)] \n",
    "\n",
    "    scale = max(x)/max(y)\n",
    "    x = x-((a//5)*scale)\n",
    "    x[x<0] = 0\n",
    "\n",
    "    top = 0\n",
    "    bottom = a-1\n",
    "\n",
    "    while(x[top]==0):\n",
    "        top += 1\n",
    "\n",
    "    while(x[bottom]==0):\n",
    "        bottom -=1\n",
    "\n",
    "\n",
    "    top = max(0, top-1)\n",
    "    bottom = min(bottom+1, a-1)\n",
    "\n",
    "    val_top = x[top]\n",
    "    val_bottom = x[bottom]\n",
    "\n",
    "    mins = [top] + list(mins) + [bottom]\n",
    "\n",
    "    for i in mins:\n",
    "        if i < a//2:\n",
    "            if x[i]<=val_top:\n",
    "                val_top = x[i]\n",
    "                top = i\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    for i in mins[::-1]:\n",
    "        if i>a//2:\n",
    "            if x[i]<=val_bottom:\n",
    "                val_bottom = x[i]\n",
    "                bottom = i\n",
    "            else:\n",
    "                continue\n",
    "    #width\n",
    "    img = img[top:bottom,:]\n",
    "    a,b = img.shape\n",
    "\n",
    "\n",
    "    x = np.sum(img, axis=0)\n",
    "    x =x*-1\n",
    "    mins, _ = find_peaks(x)\n",
    "    x =x*-1\n",
    "    y = [m for m in range(b)] \n",
    "\n",
    "    left = 0\n",
    "    right = b-1\n",
    "\n",
    "    while(x[left]==0):\n",
    "        left+=1\n",
    "\n",
    "    while(x[right]==0):\n",
    "        right-=1\n",
    "\n",
    "    for i in range(left, b//3):\n",
    "        if x[i]==a*255:\n",
    "            left = i+1\n",
    "\n",
    "\n",
    "    for i in range(2*b//3, right):\n",
    "        if x[i]==a*255:\n",
    "            right = i-1\n",
    "\n",
    "    left = max(0, left-1)\n",
    "    right = min(right+1, b-1)\n",
    "\n",
    "    val_left = x[left]\n",
    "    val_right = x[right]\n",
    "\n",
    "    mins = [left] + list(mins) + [right]\n",
    "\n",
    "    for i in mins:\n",
    "        if i < b//2:\n",
    "            if x[i]<val_left:\n",
    "                val_left = x[i]\n",
    "                left = i\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            if x[i]<=val_right:\n",
    "                val_right = x[i]\n",
    "                right = i\n",
    "            else:\n",
    "                continue\n",
    "    img = img[:, left:right]\n",
    "    a,b = img.shape\n",
    "    print(a,b, b/a)\n",
    "    brdr = a//4 if b/a > 6.4 else 15\n",
    "    constant= cv2.copyMakeBorder(img,brdr,brdr,brdr,brdr,cv2.BORDER_CONSTANT)\n",
    "    plt.imshow(constant, cmap = 'gray')\n",
    "    pre_ans = pytesseract.image_to_string(constant)\n",
    "    final_ans = \"\"\n",
    "    allowed = [chr(i) for i in range(65,91)] + [chr(i) for i in range(48,58)] + [\" \"]\n",
    "    for i in pre_ans:\n",
    "        if i not in allowed:\n",
    "            pass\n",
    "        else:\n",
    "            final_ans+=i\n",
    "    return final_ans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 490, 3)\n",
      "Tesseract Output TN 37BU 3146\n",
      "73 458 6.273972602739726\n",
      "Processed Output A URC\n",
      "-------------------------------------------------------------\n",
      "(106, 562, 3)\n",
      "Tesseract Output ~MHO1AV8866|\n",
      "66 527 7.984848484848484\n",
      "Processed Output MHOTAV8866\n",
      "-------------------------------------------------------------\n",
      "(336, 1204, 3)\n",
      "Tesseract Output MH12DE1433\n",
      "177 1145 6.468926553672317\n",
      "Processed Output MH12DE1433\n",
      "-------------------------------------------------------------\n",
      "(123, 629, 3)\n",
      "Tesseract Output MHO1 AV 6275\n",
      "94 612 6.51063829787234\n",
      "Processed Output MHO1 AV 6275\n",
      "-------------------------------------------------------------\n",
      "(149, 733, 3)\n",
      "Tesseract Output MFT T= NE SBSeD\n",
      "86 649 7.546511627906977\n",
      "Processed Output M12 NE 89\n",
      "-------------------------------------------------------------\n",
      "(257, 1100, 3)\n",
      "Tesseract Output ii 46 AU 2491)\n",
      "83 914 11.012048192771084\n",
      "Processed Output MH 46 AU 2491\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model = \"recognition/mlp.pkl\"\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 1\n",
    "rows = len(final_plates)\n",
    "for plate in final_plates:\n",
    "\n",
    "    # Load image\n",
    "    print(plate.shape)\n",
    "    ans = pytesseract.image_to_string(plate)    \n",
    "    print(\"Tesseract Output\", ans)\n",
    "    print(\"Processed Output\", new_ocr(plate, ans))\n",
    "    print(\"-------------------------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
