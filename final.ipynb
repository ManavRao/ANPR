{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Plate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameters\n",
    "\n",
    "image_name = \"images/test_3.png\"\n",
    "final_plates = []\n",
    "confThreshold = 0.5      #Confidence threshold\n",
    "nmsThreshold = 0.4       #Non-maximum suppression threshold\n",
    "\n",
    "inpWidth = 416  #608     #Width of network's input image\n",
    "inpHeight = 416 #608     #Height of network's input image\n",
    "\n",
    "save_detector = True    #Save Intermedate outputs\n",
    "\n",
    "# Load names of classes\n",
    "classesFile = \"detection/classes.names\";\n",
    "\n",
    "classes = None\n",
    "with open(classesFile, 'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "# Configuration and weight files for the model\n",
    "modelConfiguration = \"detection/darknet-yolov3.cfg\";\n",
    "modelWeights = \"detection/lapi.weights\";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "net = cv.dnn.readNetFromDarknet(modelConfiguration, modelWeights)\n",
    "net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the output layers\n",
    "def getOutputsNames(net):\n",
    "    # Get the names of all the layers in the network\n",
    "    layersNames = net.getLayerNames()\n",
    "    # Get the names of the output layers, i.e. the layers with unconnected outputs\n",
    "    return [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the predicted bounding box\n",
    "def drawPred(classId, conf, left, top, right, bottom, num):\n",
    "    # Draw a bounding box.\n",
    "    #    cv.rectangle(frame, (left, top), (right, bottom), (255, 178, 50), 3)\n",
    "    global save_detector\n",
    "    global image_name\n",
    "    global final_plates\n",
    "    temp_11 = frame[top:bottom, left:right]\n",
    "    final_plates.append(temp_11.copy())\n",
    "        \n",
    "    if save_detector:\n",
    "        temp_name = image_name.split(\"/\")[-1].split(\".\")[0] + \"_test_\"+str(num)+\".jpg\"\n",
    "        cv.imwrite(temp_name , temp_11)\n",
    "        print(\"Number plate saved as\", temp_name)\n",
    "    \n",
    "    cv.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 3)\n",
    "\n",
    "\n",
    "    label = '%.2f' % conf\n",
    "\n",
    "    # Get the label for the class name and its confidence\n",
    "    if classes:\n",
    "        assert(classId < len(classes))\n",
    "        label = '%s:%s' % (classes[classId], label)\n",
    "\n",
    "    #Display the label at the top of the bounding box\n",
    "    labelSize, baseLine = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    top = max(top, labelSize[1])\n",
    "    cv.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine), (0, 0, 255), cv.FILLED)\n",
    "    #cv.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine),    (255, 255, 255), cv.FILLED)\n",
    "    cv.putText(frame, label, (left, top), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the bounding boxes with low confidence using non-maxima suppression\n",
    "def postprocess(frame, outs):\n",
    "    frameHeight = frame.shape[0]\n",
    "    frameWidth = frame.shape[1]\n",
    "\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    # Scan through all the bounding boxes output from the network and keep only the\n",
    "    # ones with high confidence scores. Assign the box's class label as the class with the highest score.\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        print(\"out.shape : \", out.shape)\n",
    "        for detection in out:\n",
    "            #if detection[4]>0.001:\n",
    "            scores = detection[5:]\n",
    "            classId = np.argmax(scores)\n",
    "            #if scores[classId]>confThreshold:\n",
    "            confidence = scores[classId]\n",
    "            if detection[4]>confThreshold:\n",
    "                print(detection[4], \" - \", scores[classId], \" - th : \", confThreshold)\n",
    "                print(detection)\n",
    "            if confidence > confThreshold:\n",
    "                center_x = int(detection[0] * frameWidth)\n",
    "                center_y = int(detection[1] * frameHeight)\n",
    "                width = int(detection[2] * frameWidth)\n",
    "                height = int(detection[3] * frameHeight)\n",
    "                left = int(center_x - width / 2)\n",
    "                top = int(center_y - height / 2)\n",
    "                classIds.append(classId)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([left, top, width, height])\n",
    "\n",
    "    # Perform non maximum suppression to eliminate redundant overlapping boxes with\n",
    "    # lower confidences.\n",
    "    indices = cv.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        left = box[0]\n",
    "        top = box[1]\n",
    "        width = box[2]\n",
    "        height = box[3]\n",
    "        drawPred(classIds[i], confidences[i], left, top, left + width, top + height, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image file\n",
    "if not os.path.isfile(image_name):\n",
    "    raise(\"Input image file \", image_name, \" doesn't exist\")\n",
    "\n",
    "cap = cv.VideoCapture(image_name)\n",
    "outputFile = image_name.split(\"/\")[-1].split(\".\")[0] +'_yolo_out_py.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape :  (507, 6)\n",
      "0.97335917  -  0.9696169  - th :  0.5\n",
      "[0.17181729 0.67725825 0.273324   0.17995849 0.97335917 0.9696169 ]\n",
      "out.shape :  (2028, 6)\n",
      "0.876378  -  0.8753169  - th :  0.5\n",
      "[0.51376003 0.5971831  0.12284669 0.0788969  0.876378   0.8753169 ]\n",
      "out.shape :  (8112, 6)\n",
      "Number plate saved as test_3_test_0.jpg\n",
      "Number plate saved as test_3_test_1.jpg\n",
      "Done processing !!!\n",
      "Output file is stored as  test_3_yolo_out_py.jpg\n"
     ]
    }
   ],
   "source": [
    "while cv.waitKey(1) < 0:\n",
    "\n",
    "    # get frame from the video\n",
    "    hasFrame, frame = cap.read()\n",
    "\n",
    "    # Stop the program if reached end of video\n",
    "    if not hasFrame:\n",
    "        if save_detector:\n",
    "            print(\"Done processing !!!\")\n",
    "            print(\"Output file is stored as \", outputFile)\n",
    "        break\n",
    "\n",
    "    # Create a 4D blob from a frame.\n",
    "    blob = cv.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop=False)\n",
    "\n",
    "    # Sets the input to the network\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Runs the forward pass to get output of the output layers\n",
    "    outs = net.forward(getOutputsNames(net))\n",
    "\n",
    "    # Remove the bounding boxes with low confidence\n",
    "    postprocess(frame, outs)\n",
    "\n",
    "    # Put efficiency information. The function getPerfProfile returns the overall time for inference(t) and the timings for each of the layers(in layersTimes)\n",
    "    t, _ = net.getPerfProfile()\n",
    "    label = 'Inference time: %.2f ms' % (t * 1000.0 / cv.getTickFrequency())\n",
    "    #cv.putText(frame, label, (0, 15), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n",
    "\n",
    "    # Write the frame with the detection boxes\n",
    "    if save_detector:\n",
    "        cv.imwrite(outputFile, frame.astype(np.uint8));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 1\n",
    "rows = len(final_plates)\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = final_plates[i-1]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Plate Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import joblib\n",
    "import pytesseract\n",
    "from scipy.signal import find_peaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_ocr(img, ans):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    (thresh, im_bw) = cv2.threshold(img_gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    in_im_bw = cv2.bitwise_not(im_bw)\n",
    "    \n",
    "    if sum(im_bw.flatten()) < sum(in_im_bw.flatten()):\n",
    "        img = im_bw\n",
    "    else:\n",
    "        img = in_im_bw\n",
    "    #height\n",
    "    a,b = img.shape\n",
    "    x = np.sum(img, axis=1)\n",
    "\n",
    "    x = x*-1\n",
    "    mins, _ = find_peaks(x)\n",
    "    x = x*-1\n",
    "    y = [m for m in range(a)] \n",
    "\n",
    "    scale = max(x)/max(y)\n",
    "    x = x-((a//10)*scale)\n",
    "    x[x<0] = 0\n",
    "\n",
    "    top = 0\n",
    "    bottom = a-1\n",
    "\n",
    "    while(x[top]==0):\n",
    "        top += 1\n",
    "\n",
    "    while(x[bottom]==0):\n",
    "        bottom -=1\n",
    "\n",
    "\n",
    "    top = max(0, top-1)\n",
    "    bottom = min(bottom+1, a-1)\n",
    "\n",
    "    val_top = x[top]\n",
    "    val_bottom = x[bottom]\n",
    "\n",
    "    mins = [top] + list(mins) + [bottom]\n",
    "\n",
    "    for i in mins:\n",
    "        if i < a//2:\n",
    "            if x[i]<=val_top:\n",
    "                val_top = x[i]\n",
    "                top = i\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    for i in mins[::-1]:\n",
    "        if i>a//2:\n",
    "            if x[i]<=val_bottom:\n",
    "                val_bottom = x[i]\n",
    "                bottom = i\n",
    "            else:\n",
    "                continue\n",
    "    #width\n",
    "    img = img[top:bottom,:]\n",
    "    a,b = img.shape\n",
    "\n",
    "\n",
    "    x = np.sum(img, axis=0)\n",
    "    x =x*-1\n",
    "    mins, _ = find_peaks(x)\n",
    "    x =x*-1\n",
    "    y = [m for m in range(b)] \n",
    "\n",
    "    left = 0\n",
    "    right = b-1\n",
    "\n",
    "    while(x[left]==0):\n",
    "        left+=1\n",
    "\n",
    "    while(x[right]==0):\n",
    "        right-=1\n",
    "\n",
    "    for i in range(left, b//3):\n",
    "        if x[i]==a*255:\n",
    "            left = i+1\n",
    "\n",
    "\n",
    "    for i in range(2*b//3, right):\n",
    "        if x[i]==a*255:\n",
    "            right = i-1\n",
    "\n",
    "    left = max(0, left-1)\n",
    "    right = min(right+1, b-1)\n",
    "\n",
    "    val_left = x[left]\n",
    "    val_right = x[right]\n",
    "\n",
    "    mins = [left] + list(mins) + [right]\n",
    "\n",
    "    for i in mins:\n",
    "        if i < b//2:\n",
    "            if x[i]<val_left:\n",
    "                val_left = x[i]\n",
    "                left = i\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            if x[i]<=val_right:\n",
    "                val_right = x[i]\n",
    "                right = i\n",
    "            else:\n",
    "                continue\n",
    "    img = img[:, left:right]\n",
    "    a,b = img.shape\n",
    "    print(a,b, b/a)\n",
    "    brdr = int(a/2) \n",
    "    constant= cv2.copyMakeBorder(img,brdr,brdr,brdr,brdr,cv2.BORDER_CONSTANT)\n",
    "    plt.imshow(constant, cmap = 'gray')\n",
    "    pre_ans = pytesseract.image_to_string(constant)\n",
    "    final_ans = \"\"\n",
    "    allowed = [chr(i) for i in range(65,91)] + [chr(i) for i in range(48,58)] + [\" \"]\n",
    "    for i in pre_ans:\n",
    "        if i not in allowed:\n",
    "            pass\n",
    "        else:\n",
    "            final_ans+=i\n",
    "    return final_ans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269, 1092, 3)\n",
      "Tesseract Output 1H12DE1433\n",
      "190 1025 5.394736842105263\n",
      "Processed Output H12DE1433\n",
      "-------------------------------------------------------------\n",
      "(118, 490, 3)\n",
      "Tesseract Output IN 37BU 3146\n",
      "74 422 5.702702702702703\n",
      "Processed Output N37BU 3146\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model = \"recognition/mlp.pkl\"\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 1\n",
    "rows = len(final_plates)\n",
    "for plate in final_plates:\n",
    "\n",
    "    # Load image\n",
    "    print(plate.shape)\n",
    "    ans = pytesseract.image_to_string(plate)    \n",
    "    print(\"Tesseract Output\", ans)\n",
    "    print(\"Processed Output\", new_ocr(plate, ans))\n",
    "    print(\"-------------------------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
